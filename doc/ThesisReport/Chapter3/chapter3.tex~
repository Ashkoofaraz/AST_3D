\chapter{Agent}
In this chapter we are going to understand how the agent functions. Each agent consists from several parts which are described in detail.

\section{Agent Architecture}
Before seeing each part of the agent's software separately, it is time to describe the framework's architecture.  Soccer Simulation Server known as rcssserver3d is responsible for sending to our agent perception messages. Communication layer is the one that handles all the received messages and pass them to the agent. In agent layer, these messages are handled by a message parser which is responsible for updating all beliefs of the agent. Consequently, all functions that require new perceptions start then. Now, agent is free to do what the behavior tells him.
In our approach, only goalkeeper is running an independent behavior, the other eight field players start a communication procedure in order to inform the goalkeeper about the worldstate and their attributes. So, we can realize that field players do not execute any behavior. We are going to describe coordination procedure later in a separate chapter.
Communication controller and motion controller are responsible for handling the agent's requests for a message that he has to say or a movement that he has to execute. These two controller are sending in every cycle effection messages to the connection layer which will send them back to soccer simulation server.\\
\begin{figure}[htb!]
\centering
  \includegraphics[trim=1cm 2cm 1cm 2cm, clip=true,scale=0.7]{Chapter3/figures/Architecture.pdf}
  \caption{Agent's Architecture.}
  \label{fig:Architecture}
\end{figure}

\section{Connection}
The SimSpark server hosts the simulation process that manages the simulation. It is responsible for advancing the simulation. So, each agent
connects to this server. Agents receives messages from the server every 20ms; These messages includes information about all agent's perceptions.As we can see in the figure \ref{fig:Simulation-Update-Loop}, SimSpark Server send to agents sense messages in the beginning of every cycle. Each agent who is willing to send an action message, can send it in the end of his cycle, Server is going to receive at the same time it will send the next sense message.
\begin{figure}[htb!]
\centering
  \includegraphics[scale=0.4]{Chapter2/figures/800px-SimulationUpdateLoopSynchronizationBetweenSimSparkAndAgent.png}
  \caption{Simulation Update Loop.}
  \label{fig:Simulation-Update-Loop}
\end{figure}



\section{Perceptions}
Perceptions in simulation soccer are quite different in comparison with a real robots' competition. We do not receive data from agent's sensors but from the server, which send them to us in every cycle. These messages have this form:\\
\begin{verbatim}
(time (now 46.20))(GS (t 0.00) (pm BeforeKickOff))(GYR (n torso)
(rt 0.00 0.00 0.00))(ACC (n torso) (a 0.00 -0.00 9.81))(HJ (n hj
1)(ax 0.00))(HJ (n hj2) (ax 0.01))(See (G2R (pol 14.83 -11.81 1.
08))(G1R (pol 14.54 -3.66 1.12)) (F1R (pol 15.36 19.12 -1.91))(F
2R (pol 17.07 -31.86 -1.83)) (B (pol 4.51 -26.40 -6.15)) (P (tea
m AST_3D)(id 8)(rlowerarm (pol 0.18 -35.78 -21.65)) (llowerarm (
pol 0.19 34.94-21.49)))(L (pol 8.01 -60.03 -3.87) (pol 6.42 51.1
90 -39.13 -5.17))(L (pol 5.91 -39.06 -5.11) (pol 6.28-29.26 -4.8
8)) (L (pol 6.28 29.34 -4.95)(pol 6.16 -19.05 -5.00)))(HJ(n raj1
) (ax -0.01))(HJ (n raj2) (ax -0.00))(HJ (n raj3)(ax -0.00))(HJ(
n raj4) (ax 0.00))(HJ (n laj1) (ax 0.01))(HJ (n laj2) (ax 0.00))
\end{verbatim}
The above message is just an example message our agent has been sent 
during game time. It includes information about the server time, the game state and time, the values of each one of his joints and data from vision, acceleration, gyroscope and force sensors.
\begin{figure}[htb!]
\centering
  \includegraphics[scale=0.4]{Chapter3/figures/MessagesBeliefs.jpg}
  \caption{Beliefs Update.} 
  \label{fig:BeliefsUpdate}
\end{figure}
\\




\section{Localization}
Once we have all the necessary beliefs updated, it is time for us to use them in order to locate our agent in the field. Localization is created by Vassilis Papadimitriou in winter's 2011-2012 class Autonomous Agents. A brief description of the localization process is following.\\
\\
{\bf Localization Process}\\
\\
Localization process is executed every three cycles and when we receive observations from the vision perceptor. If we have visible objects in our sight we organize them in terms of their type. There are three types: Landmarks, Co-Players and Opponent Players. We make use of the Landmarks to find our position in the field.
The Nao's restricted vision perceptor limits the field of view to 120 degrees.
\begin{figure}[htb!]
\centering
  \includegraphics[scale=0.3]{Chapter3/figures/Localization1.png}
  \caption{Nao's field of view.} 
  \label{fig:fieldofview}
\end{figure}
An example of this limitation is described in the figure \ref{fig:fieldofview}.
Localization process became possible through three main functions. The first function, takes two landmarks as arguments and returns to us a possible position for our agent. If our agent sees more than two landmarks, then this function is called for every combination of two landmarks and in the end we calculate the average position. If our agent sees less than two landmarks, then he has a complete unawareness of his position in the soccer field. The figure \ref{fig:Localization} shows how this function works.
\begin{figure}[htb!]
\centering
  \includegraphics[scale=0.3]{Chapter3/figures/Localization3.png}
  \caption{Localization.} 
  \label{fig:Localization}
\end{figure}
Except from the calculation of our position in the soccer field, localization is responsible to locate ball and other agents in the field. Knowing our position helps us locate other objects too. For every other object which is locates in our field of view, vision perceptor informs us about its vertical angle, its horizontal angle and its distance from our agent. This information is enough for the calculation of their exact positions. Finally, after the localization process end, we are able to have the following observations:\\
\begin{description}
	\item[Our Position] Only if our agent sees more than one landmarks.
	\item[Body Angle] Only if our agent knows his position.
	\item[Other Agents Positions]	Only if our agent knows his position and other agents are located in the field of his view.
	\item[Ball Position] Only if our agent knows his position and ball is located in the field of his view.
\end{description}
In the figure \ref{fig:LocalizationResults} we can see the results which are given by the localization process.
\begin{figure}[htb!]
\centering
  \includegraphics[scale=0.4]{Chapter3/figures/Localization.png}
  \caption{Localization Results.} 
  \label{fig:LocalizationResults}
\end{figure}
\hfill

\section{Localization Filtering}
In absence of a stochastic localization system, we are forced to ensure that localization results are good enough for us to rely on.Due to the symmetry of the field's landmarks, localization is not always accurate enough to depend on. This, requires a kind of filtering for the observations we take by the localization process.
\begin{algorithm}[htb!]
\caption{Localization Filtering$(Observation(x,y))$}
\label{alg1}
\begin{algorithmic}[1]
\IF{$x,y \neq NaN$}
\IF{$size(Queue) = 0$}
\STATE $Queue.Add(Observation)$
\STATE $MyPosition = AVG(Queue)$
\ELSIF{$size(Queue) < Max$}
\IF{$Observation \not\approx AVG(Queue)$}
\STATE $Queue.Remove()$
\ELSE
\STATE $Queue.Add(Observation)$
\STATE $MyPosition = AVG(Queue)$
\ENDIF
\ELSE
\IF{$Observation \not\approx AVG(Queue)$}
\STATE $Queue.Remove()$
\ELSE
\STATE $Queue.Remove()$
\STATE $Queue.Add(Observation)$
\STATE $MyPosition = AVG(Queue)$
\ENDIF
\ENDIF
\ENDIF
\end{algorithmic}
\end{algorithm}
The algorithm \ref{alg1} describes the process of localization filtering. The general idea that we follow in our approach is that if our agent takes one thousand observations per minute it will be easy for him to not to take into consideration the observations with the biggest fault. In general, localization provides us with not consecutive faulty observations. To overcome this difficulty, we came up with a simple and clever approach. A queue full of observations is always gives us our agent's position in the field. When an observation is coming, we check if the queue is empty or full; If it is empty then we just add the observation into the queue. If it is full of elements, then we check if the new observation seems faulty in comparison to the average of the queue. If it seems faulty, we do not take it into account and we just remove an element from the queue. If not, then we add it to the queue.
If queue is neither empty nor full, then we make the same procedure checking if it is a faulty observation, with the only difference that we do not remove any element if it is not.Localization filtering applies for both the calculation of our agent's position and the ball's position. Its result was the improvement of the localization results in an adequate degree in order to rely on them with more confidence. This filtering smooths the belief of our position and rejects every faulty observation.
\section{Motions}
In robotics, we could define a motion as a sequence of joint poses. A pose is a set of values for every joint in the robot's body at a given time.
For example, for a given set of n-joints a pose could be defined as:\\
\begin{center}
$Pose(t)$=$\lbrace J_{1}(t),J_{2}(t),...,J_{n}(t) \rbrace$\\
\end{center}
Motions are very important part of every team take part in the simulation league. Most of the teams in this league make use of dynamic movement which is a major advantage for their side. In this approach, we are using motion files. Motion files are set of poses which has static and standard values for each joint for every movement. The difference between static motion files and dynamic movement is that dynamic movement takes into consideration the center of the body's mass and the direction in which we are want to head. This movement gives to the robot better body balance and fast movement especially in situations that the robot wants to change direction or to make a turn. In this approach we are using two kinds of static motion files. Text based and XML based motion files. Agent before initializes himself in the field read these files and saves them into the dynamic memory to be ready to use them without any need of reading them every time he needs them.



\subsection{XML Based Motions}
This motion files has been created from FIIT RoboCup 3D project. They are in XML structure and it was easy to implement them into our project. The following lines show the structure of these xml motion files.
\begin{verbatim}

		<phase name="Start" next="Phase1">
			<effectors>
				Joint Values
			</effectors>
			<duration>duration</duration>
		</phase>
		<phase name="Phase1" next="Phase2">
			<effectors>
				Joint Values
			</effectors>
			<duration>duration</duration>
		</phase>
		<phase name="Phase2"next="Phase1">
			<effectors>
				Joint Values
			</effectors>
			<duration>duration</duration>
			<finalize>Final</finalize>
		</phase>
		<phase name="Final">
			<effectors>
				Joint Values
			</effectors>
			<duration>duration</duration>
		</phase>

\end{verbatim}
It is easy to understand that each movement is split into phases. Each phase has a duration and values for every joint of the robot. Moreover,
every phase has an index which points to the next phase. For example, we see that the first phase ''Start'' has an index for the next phase: ''Phase1''. Phases with a finalize field help us to end each movement. For example, the phase:''Phase2'' has a finalize index which points to the phase: ''Final'', this means that, if we want to end this motion, we should continue the motion with the finalize phase not with the next.
\subsection{XML Based Motion Controller}
Motion controller is responsible for handling the movement requests by the agent. Agent has not access in motion controller itself but he has access in the motion trigger. We can imagine this trigger as a variable which can only be changed by the agent. Each agent declares the movement he is willing to do in this variable.
Motion controller reads this variable in every cycle and generates a string which is the result of his process.
\begin{figure}[htb!]
\centering
  \includegraphics[trim=0cm 15cm 0cm 0cm,clip=true,scale=0.4]{Chapter3/figures/MotionController.jpg}
  \caption{Motion Controller.}
  \label{fig:MotionController}
\end{figure}
In the figure \ref{fig:MotionController} we show the general architecture of the motion controller. Motion controller checks if there is a motion which is playing already. If yes, motion controller tries to finalize the playing movement in order to start playing the new requested movement.
\begin{figure}[htb!]
\centering
  \includegraphics[trim=0cm 12cm 0cm 0cm, clip=true,scale=0.4]{Chapter3/figures/MotionSequence.jpg}
  \caption{Phase Sequence.}
  \label{fig:PhaseSequence}
\end{figure}
In the next figure \ref{fig:PhaseSequence} is described the exact motion sequence. In general, XML motions is created to include cycles. For example, walking motion has three main phases which create a cycle. If motion trigger does not change at the last phase, we will continue with the first phase not with the final. As we saw in the structure of every XML based motion file, each phase has a set of joint values. These values is in degrees. To generate motion for our agent we need to create a motion string. This string holds info about the velocity we want to give in every joint involved in the motion phase. This velocity can be calculated by:
\\
\\
$Desired Velocity$ = $Already Joint Value$ - $Desired Joint Value$\\
\\
This is the velocity of every joint. Furthermore, every phase has a duration in which has to be executed. So, phase duration has to be divide with the duration of every server cycle. This will give us the number of cycles this phase will be playing.\\
\\
$Cycles Number = \frac {Phase Duration} {Cycle Duration}$\\
\\
Now, we have the phase's velocity and the duration in cycles. We can calculate, how much will be the speed of every joint in order to reach to the desired joint value in this time limit.\\
\\
$Velocity = \frac {Desired Velocity} {Cycles Number} degrees/sec$\\
\\
This velocity is calculated for every involved joint in the motion. The final output of the motion controller will be send to the server.



\subsection{Text Based Motions}
The other kind of motion files that we use is created by Webots simulator. These text based motion files have simpler structure than the XML have. At the second row, there are the definition for all joints which are related to  each motion. For example, walking motion requires only the joints from both robot's legs. The next rows from left to right have information for the duration of each pose, the pose name and finally the joints' values for each joint in the same order as they are defined in the second row.
\begin{verbatim}
#WEBOTS_MOTION,V1.0
LHipYawPitch,LHipRoll,LHipPitch,LKneePitch,LAnklePitch,...
00:00:000,Pose1,0,-0.012,-0.525,1.05,-0.525,0.012,0,...
00:00:040,Pose2,0,-0.011,-0.525,1.05,-0.525,0.011,0,...
00:00:080,Pose3,0,-0.009,-0.525,1.05,-0.525,0.009,0,...
00:00:120,Pose4,0,-0.007,-0.525,1.05,-0.525,0.007,0,...
00:00:160,Pose5,0,-0.004,-0.525,1.05,-0.525,0.004,0,...
00:00:200,Pose6,0,0.001,-0.525,1.051,-0.525,-0.001,0,...
00:00:240,Pose7,0,0.006,-0.525,1.05,-0.525,-0.006,0,...
00:00:280,Pose8,0,0.012,-0.525,1.05,-0.525,-0.012,0,...
00:00:320,Pose9,0,0.024,-0.525,1.05,-0.525,-0.024,0,...
\end{verbatim}
\subsection{Text Based Motion Controller}
Motion controller for text based motions is based on the same principle as the XML controller. The joint values in the motion files represent
radians. So we convert these values into degrees and then we proceed with next steps. Each pose lasts for one or two cycles depending on the speed we want each motion to be executed. This motion controller could be customized easily to perform motions differently. There are parameters that can be changed such as:
\begin{description}
	\item[Speed] How fast we want pose to be executed.
	\item[Duration]	How many cycles from pose to pose.
	\item[Pose Offset] Pose Offset = 2, we execute pose1,pose3,pose5,...
	\item[Hardness Factor]	Hardness Factor = 0.9, we multiply the velocity with this factor.
\end{description}
The velocity of every joint is calculated by:\\
\\
$Desired Velocity$ = $Already Joint Value$ - $RadiansToDegrees(Desired Joint Value)$
\\
\\
$Velocity = \frac {Desired Velocity \ast Hardness Factor} {Speed} degrees/sec$\\
\\
This velocity is calculated for every involved joint in the motion. The final output of the motion controller will be send to the server.





\section{Actions}
Actions are the results of the agent's perception in combination with his procedure of thinking.
In our approach actions are split into groups in terms of their complexity and their type. 

\subsection{Simple}
First of all, simple actions which are make use only motions and have a simple structure. These simple actions are:
\begin{description}
 \item[TurnToSeeBall] This action results in turning the agent until ball is in his field of view.
 \item[TurnToBall] This action turns agent towards the ball.
 \item[TurnToLocate] This is the default action each agent does when he loses his position ( sees less than two landmarks ) in the field.
 \item[WalkToBall] Agent walks towards the ball. He stops when the ball is close enough to him to shoot it.
 \item[StandUp] Agent executes it when he is fallen on the ground.
 \item[PrepareKick] Agent executes it before performs a kick. This action is needed in order to have a successful kick.
\end{description}

\subsection{Complex}
Complex actions are created to make use of more than one simple actions and motions and have a more complicated structure. These complex actions are:
\begin{description}
 \item[GoKickBallToGoal] This action uses WalkToBall in order the agent to reach the ball. In this action we use the agent's belief about his location in the field to help us find the direction in which the agent has to kick the ball. This action has a fsm logic. Figure \ref{fig:GoKickBallToGoal} shows how looks like this action's execution.
 \begin{figure}[!h]
\centering
  \includegraphics[trim=0cm 0cm 0cm 0cm, clip=true,scale=0.3]{Chapter3/figures/KickFsm.jpg}
  \caption{GoKickBallToGoal Action.}
  \label{fig:GoKickBallToGoal}
\end{figure}
 \item[GoClearBall] This action uses WalkToBall in order the agent to reach the ball. In this action we use the agent's belief about his location in the field to help us find the direction in which the agent should not kick the ball.
 \item[WalkToCoordinate]
 This action takes the agent to a specific coordinate in the soccer field. To achieve this action we need to know our position in the field and the target coordinate. Agent is able to know his position so it is easy for us to calculate in which direction agent has to walk in order to get in the specific coordinate. The figure \ref{fig:WalkToCoordinate} shows us that agent should travel from the point $(X_{start},Y_{start})$, to the point $(X_{target},Y_{target})$. It is easy to find $\vartheta_{target}^{\circ}$:\\
$\partial_{X} = X_{target} - X_{start}$\\
$\partial_{Y} = Y_{target} - Y_{start}$\\
$\vartheta_{target}^{\circ} = atan2(\partial_{X},\partial_{Y})$\\
\\
With these calculations our agent is always aware of the distance and the direction he has to travel. 
 \begin{figure}[!h]
\centering
  \includegraphics[trim=0cm 0cm 0cm 0cm, clip=true,scale=0.3]{Chapter3/figures/WalkToCoordinate.png}
  \caption{WalkToCoordinate.}
  \label{fig:WalkToCoordinate}
\end{figure} 
 \item[WalkToDirection]
 With this action agent walks towards a specific direction.
 \item[WalkWithBallToDirection}
 As far as agent reaches the ball, he will try to keep the ball in front of him and walk towards a direction keeping into mind that the ball has to be always in front of him.
\end{description}

\subsection{Vision}
Vision related actions are created to control the vision perceptor which is attached to the robot's head as well as to collect data from this perceptor in order to execute related actions such as obstacle avoidance. These vision related actions are:
\begin{description}
 \item[MoveHead] This action is related with the movement of the head. Nao robot has two joints attached in the neck which give us the freedom of moving the head in relation to the action is being performed.
 \begin{description}
 \item[type 1] Head moves to its original position.
 \item[type 2] Head moves until agent see the ball.
 \item[type 3] Head moves in relation to the ball's movement.
 \item[type 4] Head make a harmonic movement in order agent to have a nice perception of his environment.
 \item[type 5] Head moves until agent can localize himself in the field.
 \end{description}
 \item[WatchObjectMovement] This action requires that object is in agent's field of view. Knowing the direction and the speed of the moving object is only feasible if we keep in memory a short number of observations. We keep two sets of five observations which we take within a time difference. Finding the average position of each set gives a distance between these two positions. If this distance will be divided with the time difference of the two observation set we are going to have the direction and the speed of the moving object.
 \item[FindOpponentsGoal]This action is used in GoKickBallToGoal in order to take observations about the direction of the opponents goal in relation to agent's body angle.
 \item[ObstaclePerceptor]
 Obstacle Perceptor is an action that has the responsibility of having a good view of all obstacles that there are in our close range. Due to the fact that simulated nao's head can move in horizontal axis from $120^{\circ}$ to $-120^{\circ}$ and our field of view is $120^{\circ}$ means that we can have a complete imaging from all obstacles which are located close to our agent.
 So, in every cycle of Nao's head we save all obstacles in an array. It is usual to observe the same obstacle more than once, at this situation we find the average of these of observations. At the end of head's cycle we call the main action which tries to find alternative routes if there is an obstacle in our way.
 \item[ObstacleAvoidance]
 In a dynamic and a multi-agent environment like simulation soccer this action is more than neccessary. However, there are       some teams in simulated soccer competition which have not yet          develop an obstacle avoidance system. In our framework there is a
 reliable and a well-tested system to avoid possible collisions.
  \begin{figure}[!h]
\centering
  \includegraphics[trim=0cm 0cm 0cm 0cm, clip=true,scale=0.65]{Chapter3/figures/ObstacleAvoidance.png}
  \caption{Obstacle Avoidance.}
  \label{fig:ObstacleAvoidance}
\end{figure} 
\end{description}
The figure \ref{fig:ObstacleAvoidance} shows an example where there are two obstacles between the agent and his target. During his walking to his target agent scans the field for possible obstacles. If agent realizes that there is an object which blocks his way to the target in the same simulation cycle he starts calculate the possible way out angles that he could choose in relation to his observation about all obstacles. For every obstacle we calculate a set of two angles. These angles is determined by the distance between our agent and the obstacle and they show in which direction we can avoid this obstacle. When these angles are calculated, we check each angle of each set if it belongs to another angle set as well. Angles which belongs to another set are removed from the final list. This process is described as a pseudo-code \ref{alg2}.
\begin{algorithm}[htb!]
\caption{Way Out Angle Set}
\label{alg2}
\begin{algorithmic}[1]
\STATE $Obstacles = \lbrace O_{1},O_{2},...,O_{n} \rbrace $
\FOR{{\bf each} i in Obstacles}
\STATE $WayOutSet.Add(Calculate(O_{a},t))$
\ENDFOR
\FOR{{\bf each} j in WayOutSet}
\FOR{{\bf each} t in $\lbrace r, l \rbrace$}
\IF{$WayOutSet_{j,t} \in WayOutSet_{k}, \vee k \in \lbrace 1,2 \ast n \rbrace , k \neq j$}
\STATE $WayOutSet.Remove(j,t)$
\ENDIF
\ENDFOR
\ENDFOR
\end{algorithmic}
\end{algorithm}
Once we have all the qualified angle sets from the algorithm, it is time to find coordinates which are safe in order to avoid the obstacle. For each angle in these sets we calculate a specific coordinate. These coordinates in the soccer field will give us routes that are safe to follow. Now, we are going to calculate the cost for each route in respect with our body angle, the whole distance we have to travel to target if we follow this route. The route with the minimum cost is qualified to be followed by the agent.


\subsection{Other Sensors}
Other Sensors related actions are created to collect data from gyroscope, accelerometer and force resistance perceptors. In this category there is only one action. This action is called {\bf CheckIfFall} and is responsible to check if our agent is fallen on the ground. In a multi-agent environment like this we should be aware about possible collisions with other agents or falls because the instability of movement. First of all, incoming perceptual inputs related to both gyroscope and accelerometer values are used to detect whether the robot has become subject of a big turmoil. Taking values  above a threshold from these two perceptors, it is possible that the robot has fallen, but not completely sure to perform a stand up action yet. It is not unusual to receive values above threshold due to a collision without a fall. So, we have to check the force resistance perceptors which are located under agent's feet. If these perceptors imply that the legs do not touch the ground then we are pretty sure to perform a stand up action.Foot pressure value is also used to determine whether the stand up action is succeeded.


\section{Communication}
Communication in simspark is not ideal. There are not restrictions about the say effector and every player can use it in every cycle. However, the hear perceptor comes up with some restrictions. Messages should not have a length more than twenty characters from the ASCII subset [0x21; 0x7E] excluding [0x28; 0x29] which are the parenthesis characters, ( and ). Messages shouted from beyond a maximal distance (currently 50 meters) cannot be heard. Note that as the field is currently only 20x30 meters (36 diagonally), this does not turn out to be a limit in practice. The number of messages which can be heard at the same time is bounded. Finally, each player has the maximal capacity of one heard message by a specific team every two simulation cycles (thus every 0.04 seconds per team). Due to the limited communication bandwidth we utilize the communication channel in the following way, making sure that every message which is sent from an agent will be heard by other agents in time. A simple communication protocol is created in which time is sliced into pieces each one of them lasts for one cycle (2ms) and repeats every three cycles (6ms). Figure \ref{fig:TimeSlicing} shows how time is sliced. Every three cycles there is one of these piece in which only one agent is able to send his message to the others. Every one of these slices has an integer label on it which states the uniform number of the player which is able to send his message. This label grows by one in every time a player send his message until it reaches the maximum uniform number, then it returns to the number one. Agents are not permitted to use a common chronometer for this task but we make sure that each player is synchronized with the others making use of the changing game states. By using this simple protocol we achieve that every player can receive the other eight agents' messages in just 54ms.
\begin{figure}[!h]
\centering
  \includegraphics[trim=0cm 0cm 0cm 0cm, clip=true,scale=0.1]{Chapter3/figures/TimeSlicing.png}
  \caption{Time Slices.}
  \label{fig:TimeSlicing}
\end{figure} 